# -*- coding: utf-8 -*-
"""MC_assignment03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17FnaYMkUYtRqjPo59LxnAegxEaMdRnqk
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import numpy as np

# Load the data
data = pd.read_csv("dataset.csv", delimiter="\t", header=None)

# Rename the columns
data.columns = ['ID', 'Sample', 'Timestamp', 'Feature1', 'Feature2', 'Feature3']

# Drop unnecessary columns
data.drop(['ID', 'Sample', 'Timestamp'], axis=1, inplace=True)

# Separate features and target variables
X = data.iloc[:, :-3]  # Features
y = data.iloc[:, -3:]  # Target variables

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Regressor model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions on the testing data
y_pred = model.predict(X_test)

# Evaluate the model using Root Mean Squared Error (RMSE)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Root Mean Squared Error:", rmse)

# Predict for the next 10 seconds
# Assuming X_test contains the last observed data, we can simply predict the next 10 seconds
next_10_seconds = model.predict(X_test.tail(1))  # Predict for the last observed data
print("Predictions for the next 10 seconds:")
print(next_10_seconds)